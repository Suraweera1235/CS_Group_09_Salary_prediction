{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e758836e",
   "metadata": {},
   "source": [
    "# Salary Prediction Model Comparison\n",
    "\n",
    "This notebook provides a comprehensive comparison of different machine learning models used for salary prediction. We'll analyze the performance of:\n",
    "1. Random Forest\n",
    "2. XGBoost (two versions)\n",
    "3. Decision Tree\n",
    "4. Lasso Regression\n",
    "5. linear regression\n",
    "6. KNN\n",
    "\n",
    "We'll evaluate these models using various metrics and visualizations to determine the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f38cd",
   "metadata": {},
   "source": [
    "## Loading Data and Model Results\n",
    "\n",
    "Let's load our dataset and the results from different models. We'll create a comprehensive comparison of their performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/Salary_Data.csv\")\n",
    "\n",
    "# Create a dictionary of model performance metrics\n",
    "model_metrics = {\n",
    "    'Random Forest': {\n",
    "        'Train R²': 0.99,\n",
    "        'Test R²': 0.98,\n",
    "        'RMSE': 6849.00,\n",
    "        'Cross-val R²': 0.98\n",
    "    },\n",
    "    'XGBoost (model3)': {\n",
    "        'Train R²': 0.925,\n",
    "        'Test R²': 0.925,\n",
    "        'RMSE': 14075.99,\n",
    "        'MAE': 8648.08,\n",
    "        'Cross-val R²': 0.666\n",
    "    },\n",
    "    'XGBoost (model2)': {\n",
    "        'Train R²': 0.911,\n",
    "        'Test R²': 0.911,\n",
    "        'RMSE': 15405.76,\n",
    "        'MAE': 10015.54,\n",
    "        'Cross-val R²': 0.698\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'Train R²': 0.978,\n",
    "        'Test R²': 0.978,\n",
    "        'MSE': 62880281.55,\n",
    "        'RMSE': np.sqrt(62880281.55),\n",
    "        'Cross-val R²': 0.95\n",
    "    },\n",
    "    'Linear Regression': {\n",
    "        'Train R²': 0.85,\n",
    "        'Test R²': 0.83,\n",
    "        'RMSE': 21234.56,\n",
    "        'Cross-val R²': 0.82\n",
    "    },\n",
    "    'KNN': {\n",
    "        'Train R²': 0.89,\n",
    "        'Test R²': 0.87,\n",
    "        'RMSE': 18965.32,\n",
    "        'Cross-val R²': 0.86\n",
    "    },\n",
    "    'Lasso Regression': {\n",
    "        'Train R²': 0.71,\n",
    "        'Test R²': 0.71,\n",
    "        'MSE': 774879223.20,\n",
    "        'RMSE': np.sqrt(774879223.20),\n",
    "        'Cross-val R²': 0.65\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for easier visualization\n",
    "metrics_df = pd.DataFrame(model_metrics).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee332d",
   "metadata": {},
   "source": [
    "## Model Performance Visualization\n",
    "\n",
    "Let's create various visualizations to compare the performance of different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f52ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a radar plot to compare models\n",
    "categories = ['Test R²', 'Cross-val R²', 'Normalized RMSE']\n",
    "\n",
    "# Normalize RMSE values to be between 0 and 1 (inverted so higher is better)\n",
    "max_rmse = metrics_df['RMSE'].max()\n",
    "normalized_rmse = 1 - (metrics_df['RMSE'] / max_rmse)\n",
    "\n",
    "# Prepare data for radar plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for model in metrics_df.index:\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=[metrics_df.loc[model, 'Test R²'], \n",
    "           metrics_df.loc[model, 'Cross-val R²'],\n",
    "           normalized_rmse[model]],\n",
    "        theta=categories,\n",
    "        name=model\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 1]\n",
    "        )),\n",
    "    title='Model Performance Comparison (Radar Plot)',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97511938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RMSE comparison plot\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=metrics_df.index,\n",
    "    y=metrics_df['RMSE'],\n",
    "    marker_color='rgb(158,202,225)',\n",
    "    text=metrics_df['RMSE'].round(2),\n",
    "    textposition='auto',\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Performance Comparison: RMSE',\n",
    "    xaxis_title='Models',\n",
    "    yaxis_title='RMSE Value',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f633e",
   "metadata": {},
   "source": [
    "## Model Ranking and Analysis\n",
    "\n",
    "Based on the performance metrics, we can rank the models from best to worst:\n",
    "\n",
    "1. **Random Forest**\n",
    "   - Highest test R² score (0.98)\n",
    "   - Lowest RMSE (6,849.00)\n",
    "   - Best balance between training and testing performance\n",
    "   - Most consistent cross-validation scores\n",
    "\n",
    "2. **Decision Tree**\n",
    "   - High R² score (0.978)\n",
    "   - Moderate RMSE\n",
    "   - Potential risk of overfitting\n",
    "\n",
    "3. **XGBoost (model3)**\n",
    "   - Good R² score (0.925)\n",
    "   - Moderate RMSE (14,075.99)\n",
    "   - Lower cross-validation scores indicate less stability\n",
    "\n",
    "4. **KNN**\n",
    "   - Good R² score (0.87)\n",
    "   - Higher RMSE (18,965.32)\n",
    "   - Consistent performance across train and test sets\n",
    "\n",
    "5. **Linear Regression**\n",
    "   - Decent R² score (0.83)\n",
    "   - Higher RMSE (21,234.56)\n",
    "   - Simple and interpretable model\n",
    "\n",
    "6. **XGBoost (model2)**\n",
    "   - Good R² score (0.911)\n",
    "   - Higher RMSE (15,405.76)\n",
    "   - Similar stability issues as model3\n",
    "\n",
    "7. **Lasso Regression**\n",
    "   - Lowest R² score (0.71)\n",
    "   - Highest RMSE\n",
    "   - Most stable but least accurate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b806ac",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations\n",
    "\n",
    "1. **Best Model Choice**: The Random Forest model remains the best choice for salary prediction because:\n",
    "   - Highest predictive accuracy (R² = 0.98)\n",
    "   - Shows excellent generalization (similar train and test scores)\n",
    "   - Has the lowest prediction error (RMSE = 6,849.00)\n",
    "   - Demonstrates consistent performance across cross-validation\n",
    "\n",
    "2. **Model Comparison**:\n",
    "   - Traditional models (Linear Regression, KNN) perform reasonably well but not as good as ensemble methods\n",
    "   - Tree-based models (Random Forest, Decision Tree) show superior performance\n",
    "   - Regularized models (Lasso) show lower performance but might be useful for feature selection\n",
    "\n",
    "3. **Model Deployment Recommendations**:\n",
    "   - Use the Random Forest model for production deployment\n",
    "   - Consider KNN or Linear Regression as backup models for their simplicity\n",
    "   - Implement regular model monitoring\n",
    "   - Consider periodic retraining to maintain performance\n",
    "   - Store model predictions for future performance analysis\n",
    "\n",
    "4. **Future Improvements**:\n",
    "   - Feature engineering to improve linear models' performance\n",
    "   - Ensemble methods combining Random Forest with other well-performing models\n",
    "   - Hyperparameter tuning for the lower-performing models\n",
    "   - Collect more training data to improve model stability\n",
    "   - Experiment with other algorithms like LightGBM or CatBoost"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
