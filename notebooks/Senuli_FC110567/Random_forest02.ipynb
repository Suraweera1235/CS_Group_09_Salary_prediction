{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4fe708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> RMSE: 4,278.28 | R2: 0.9934 | MAE: 2,097.76\n",
      "Test -> RMSE: 8,072.71 | R2: 0.9758 | MAE: 3,558.40\n",
      "CV R2 mean: 0.9810 (+/- 0.0066)\n",
      "\n",
      "Best params: {'rf_ttr__regressor__n_estimators': 100, 'rf_ttr__regressor__min_samples_split': 5, 'rf_ttr__regressor__min_samples_leaf': 1, 'rf_ttr__regressor__max_features': 0.5, 'rf_ttr__regressor__max_depth': 15}\n",
      "Model saved to ../../models/rf_alt_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"../../data/Salary_Data.csv\")\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Basic winsorization (cap extremes at 1st and 99th percentiles) to reduce effect of extreme outliers\n",
    "for col in ['Age', 'Years of Experience', 'Salary']:\n",
    "    lower, upper = df[col].quantile([0.01, 0.99])\n",
    "    df[col] = df[col].clip(lower=lower, upper=upper)\n",
    "\n",
    "# Features / target\n",
    "X = df.drop(columns=['Salary'])\n",
    "y = df['Salary']\n",
    "\n",
    "# Train/test split (stratify on Gender if present)\n",
    "strat_col = None\n",
    "if 'Gender' in X.columns and X['Gender'].nunique() > 1:\n",
    "    strat_col = X['Gender']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=strat_col\n",
    ")\n",
    "\n",
    "# Create some new features using only training data (avoid leakage)\n",
    "# 1) Experience to age ratio\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "X_train['exp_age_ratio'] = X_train['Years of Experience'] / (X_train['Age'] + 1)\n",
    "X_test['exp_age_ratio'] = X_test['Years of Experience'] / (X_test['Age'] + 1)\n",
    "\n",
    "# 2) Target-encoding for Job Title (map training target means)\n",
    "if 'Job Title' in X_train.columns:\n",
    "    df_te = X_train.join(y_train.rename('Salary'))\n",
    "    job_title_te = df_te.groupby('Job Title')['Salary'].mean()\n",
    "    X_train['job_title_te'] = X_train['Job Title'].map(job_title_te).fillna(job_title_te.mean())\n",
    "    X_test['job_title_te'] = X_test['Job Title'].map(job_title_te).fillna(job_title_te.mean())\n",
    "else:\n",
    "    X_train['job_title_te'] = 0\n",
    "    X_test['job_title_te'] = 0\n",
    "\n",
    "# 3) Ordinal encoding for Education Level based on training-target ordering\n",
    "if 'Education Level' in X_train.columns:\n",
    "    edu_order = df_te.groupby('Education Level')['Salary'].mean().sort_values().index.tolist()\n",
    "    edu_map = {k: i for i, k in enumerate(edu_order)}\n",
    "    X_train['education_ord'] = X_train['Education Level'].map(edu_map).fillna(-1)\n",
    "    X_test['education_ord'] = X_test['Education Level'].map(edu_map).fillna(-1)\n",
    "else:\n",
    "    X_train['education_ord'] = 0\n",
    "    X_test['education_ord'] = 0\n",
    "\n",
    "# Define columns for preprocessing\n",
    "num_cols = ['Age', 'Years of Experience', 'exp_age_ratio', 'job_title_te', 'education_ord']\n",
    "cat_cols = []\n",
    "if 'Gender' in X_train.columns:\n",
    "    cat_cols.append('Gender')\n",
    "\n",
    "# Preprocessor: KBins for Age (quantile bins) + scaling; OneHot for Gender\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('kb_age', KBinsDiscretizer(n_bins=5, encode='onehot-dense', strategy='quantile'), ['Age']),\n",
    "    ('num', StandardScaler(), ['Years of Experience', 'exp_age_ratio', 'job_title_te', 'education_ord']),\n",
    "    ('gender', OneHotEncoder(drop='if_binary', handle_unknown='ignore'), cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "# Base estimator\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Wrap with log-target transform to stabilize variance\n",
    "ttr = TransformedTargetRegressor(regressor=rf, func=np.log1p, inverse_func=np.expm1)\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('pre', preprocessor),\n",
    "    ('rf_ttr', ttr)\n",
    "])\n",
    "\n",
    "# Hyperparameter space for randomized search\n",
    "param_dist = {\n",
    "    'rf_ttr__regressor__n_estimators': [100, 200, 300],\n",
    "    'rf_ttr__regressor__max_depth': [6, 10, 15, None],\n",
    "    'rf_ttr__regressor__max_features': ['sqrt', 'log2', 0.5],\n",
    "    'rf_ttr__regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'rf_ttr__regressor__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Cross-validation and randomized search (light)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, param_distributions=param_dist, n_iter=12, cv=cv,\n",
    "    scoring='r2', random_state=42, n_jobs=-1, verbose=0\n",
    ")\n",
    "\n",
    "# Fit\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Best pipeline\n",
    "best_pipe = search.best_estimator_\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_train_pred = best_pipe.predict(X_train)\n",
    "y_test_pred = best_pipe.predict(X_test)\n",
    "\n",
    "def evaluate(y_true, y_pred, name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"{name} -> RMSE: {rmse:,.2f} | R2: {r2:.4f} | MAE: {mae:,.2f}\")\n",
    "    return {'rmse': rmse, 'r2': r2, 'mae': mae}\n",
    "\n",
    "train_metrics = evaluate(y_train, y_train_pred, \"Train\")\n",
    "test_metrics = evaluate(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# Cross-val on training set with best pipeline\n",
    "cv_scores = cross_val_score(best_pipe, X_train, y_train, cv=cv, scoring='r2', n_jobs=-1)\n",
    "print(f\"CV R2 mean: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "# Save model\n",
    "import os\n",
    "os.makedirs(\"../../models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(best_pipe, \"../../models/rf_alt_model.joblib\")\n",
    "\n",
    "# Print selected features / notes\n",
    "print(\"\\nBest params:\", search.best_params_)\n",
    "print(\"Model saved to ../../models/rf_alt_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
